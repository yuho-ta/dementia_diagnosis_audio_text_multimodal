#!/usr/bin/env python3
# =============================
# ãƒã‚¤ã‚ºè¿½åŠ ä»˜ãwav2vecç‰¹å¾´é‡åˆ†é¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
# - ãƒã‚¤ã‚ºè¿½åŠ ä»˜ãwav2vecç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¦åˆ†é¡
# - å„ãƒã‚¤ã‚ºã‚¿ã‚¤ãƒ—ã”ã¨ã®æ€§èƒ½æ¯”è¼ƒ
# - ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹è©•ä¾¡
# - çµæœã®å¯è¦–åŒ–ã¨ä¿å­˜
# - è¢«é¨“è€…IDãƒ™ãƒ¼ã‚¹ã®åˆ†å‰²ï¼ˆåŒã˜è¢«é¨“è€…ã®ãƒ‡ãƒ¼ã‚¿ãŒtrain/testã«æ··åœ¨ã—ãªã„ï¼‰
# =============================

import os
import yaml
import argparse
import logging
import pandas as pd
import json

from noise_augmented_utils import set_seed, setup_logging
from noise_augmented_experiments import process_single_noise_type, process_noise_combination_experiment

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    # ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®š
    set_seed(42)
    
    # ãƒ­ã‚°è¨­å®š
    logger = setup_logging()
    
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    config_path = os.path.join('configs', 'noise_augmented_wav2vec.yaml')
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    import torch
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.info(f"Using device: {device}")
    
    # ãƒ‘ã‚¹è¨­å®š
    features_path = os.path.join('dataset', 'diagnosis', 'train', 'noise_augmented_features')
    output_path = os.path.join('results', 'noise_augmented_classification')
    os.makedirs(output_path, exist_ok=True)
    
    # åˆ†é¡è¨­å®š
    classification_config = config['classification']
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ
    parser = argparse.ArgumentParser(description='Noise augmented classification with subject-based splitting')
    parser.add_argument('--experiment', type=str, default='single_noise', 
                       choices=['single_noise', 'noise_combination'],
                       help='Experiment type: single_noise or noise_combination')
    
    args = parser.parse_args()
    
    if args.experiment == 'single_noise':
        # å˜ä¸€ãƒã‚¤ã‚ºã‚¿ã‚¤ãƒ—ã®å®Ÿé¨“
        logger.info("Starting noise augmented classification comparison with subject-based splitting...")
        
        # ã™ã¹ã¦ã®ãƒã‚¤ã‚ºã‚¿ã‚¤ãƒ—ã‚’å‡¦ç†
        logger.info("Processing all available noise types with subject-based cross-validation")
        logger.info("Using StratifiedGroupKFold to ensure no subject data appears in both train and test sets")
        available_noise_types = [
            ('gaussian_noise_light', 'gaussian_noise_light', 'original')
        ]
        logger.info(f"Found {len(available_noise_types)} noise types: {available_noise_types}")
        
        all_results = {}
        for train_noise_types, val_noise_types, test_noise_type in available_noise_types:
            logger.info(f"\n{'='*50}")
            logger.info(f"Processing noise type: train_noise_types={train_noise_types}, val_noise_types={val_noise_types}, test_noise_type={test_noise_type}")
            logger.info(f"{'='*50}")
            
            try:
                result = process_single_noise_type(train_noise_types, val_noise_types, test_noise_type, features_path, classification_config, config, device, output_path)
                if result:
                    all_results[train_noise_types + '_' + val_noise_types + '_' + test_noise_type] = result
                    logger.info(f"âœ“ Completed processing for train_noise_types={train_noise_types}, val_noise_types={val_noise_types}, test_noise_type={test_noise_type}")
                    logger.info(f"  Validation Accuracy: {result['mean_validation_accuracy']:.4f} Â± {result['std_validation_accuracy']:.4f}")
                    logger.info(f"  Test Accuracy: {result['mean_test_accuracy']:.4f} Â± {result['std_test_accuracy']:.4f}")
                    logger.info(f"  Test F1: {result['mean_test_f1']:.4f} Â± {result['std_test_f1']:.4f}")
                else:
                    logger.error(f"âœ— Failed to process noise type: train_noise_types={train_noise_types}, val_noise_types={val_noise_types}, test_noise_type={test_noise_type}")
            except Exception as e:
                logger.error(f"âœ— Error processing noise type train_noise_types={train_noise_types}, val_noise_types={val_noise_types}, test_noise_type={test_noise_type}: {str(e)}")
                continue
        
        # å…¨çµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        if all_results:
            logger.info(f"\n{'='*50}")
            logger.info("SUMMARY OF ALL NOISE COMBINATIONS")
            logger.info(f"{'='*50}")
            
            # çµæœã‚’ãƒ†ã‚¹ãƒˆç²¾åº¦é †ã«ã‚½ãƒ¼ãƒˆ
            sorted_results = sorted(all_results.items(), key=lambda x: x[1]['mean_test_accuracy'], reverse=True)
            
            for i, (noise_combination, result) in enumerate(sorted_results, 1):
                logger.info(f"{i}. {noise_combination}:")
                logger.info(f"   Validation Accuracy: {result['mean_validation_accuracy']:.4f} Â± {result['std_validation_accuracy']:.4f}")
                logger.info(f"   Test Accuracy: {result['mean_test_accuracy']:.4f} Â± {result['std_test_accuracy']:.4f}")
                logger.info(f"   Test F1 Score: {result['mean_test_f1']:.4f} Â± {result['std_test_f1']:.4f}")
            
            # æœ€è‰¯ã®çµæœã‚’å¼·èª¿ï¼ˆãƒ†ã‚¹ãƒˆç²¾åº¦ã§è©•ä¾¡ï¼‰
            best_noise_combination, best_result = sorted_results[0]
            logger.info(f"\nğŸ† BEST PERFORMANCE: {best_noise_combination}")
            logger.info(f"   Validation Accuracy: {best_result['mean_validation_accuracy']:.4f} Â± {best_result['std_validation_accuracy']:.4f}")
            logger.info(f"   Test Accuracy: {best_result['mean_test_accuracy']:.4f} Â± {best_result['std_test_accuracy']:.4f}")
            logger.info(f"   Test F1 Score: {best_result['mean_test_f1']:.4f} Â± {best_result['std_test_f1']:.4f}")
            
            # çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            summary_df = pd.DataFrame([
                {
                    'noise_combination': noise_combination,
                    'mean_validation_accuracy': result['mean_validation_accuracy'],
                    'std_validation_accuracy': result['std_validation_accuracy'],
                    'mean_test_accuracy': result['mean_test_accuracy'],
                    'std_test_accuracy': result['std_test_accuracy'],
                    'mean_test_f1': result['mean_test_f1'],
                    'std_test_f1': result['std_test_f1']
                }
                for noise_combination, result in sorted_results
            ])
            
            summary_path = os.path.join(output_path, 'all_noise_types_summary.csv')
            summary_df.to_csv(summary_path, index=False)
            logger.info(f"\nSummary saved to: {summary_path}")
            
        else:
            logger.warning("No results to summarize")
        
        logger.info("Noise augmented classification comparison with subject-based splitting completed!")
        
    elif args.experiment == 'noise_combination':
        # ãƒã‚¤ã‚ºã®çµ„ã¿åˆã‚ã›å®Ÿé¨“
        logger.info("Starting noise combination experiment with subject-based splitting...")
        logger.info("Testing combinations of train and test noise types")
        logger.info("Ensuring no subject overlap between train and test sets")
        
        all_results = process_noise_combination_experiment(features_path, classification_config, config, device, output_path)
        
        if all_results:
            logger.info("Noise combination experiment completed successfully!")
            
            # çµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
            logger.info(f"\n{'='*60}")
            logger.info("NOISE COMBINATION EXPERIMENT SUMMARY")
            logger.info(f"{'='*60}")
            
            # çµæœã‚’ãƒ†ã‚¹ãƒˆç²¾åº¦é †ã«ã‚½ãƒ¼ãƒˆ
            sorted_results = sorted(all_results.items(), key=lambda x: x[1]['mean_test_accuracy'], reverse=True)
            
            for i, (exp_name, result) in enumerate(sorted_results, 1):
                logger.info(f"\n{i}. {exp_name}:")
                logger.info(f"   Train noise types: {result['train_noise_types']}")
                logger.info(f"   Test noise type: {result['test_noise_type']}")
                logger.info(f"   Validation Accuracy: {result['mean_validation_accuracy']:.4f} Â± {result['std_validation_accuracy']:.4f}")
                logger.info(f"   Test Accuracy: {result['mean_test_accuracy']:.4f} Â± {result['std_test_accuracy']:.4f}")
                logger.info(f"   Test F1 Score: {result['mean_test_f1']:.4f} Â± {result['std_test_f1']:.4f}")
            
            # æœ€è‰¯ã®çµæœã‚’å¼·èª¿ï¼ˆãƒ†ã‚¹ãƒˆç²¾åº¦ã§è©•ä¾¡ï¼‰
            best_exp_name, best_result = sorted_results[0]
            logger.info(f"\nğŸ† BEST PERFORMANCE: {best_exp_name}")
            logger.info(f"   Train noise types: {best_result['train_noise_types']}")
            logger.info(f"   Test noise type: {best_result['test_noise_type']}")
            logger.info(f"   Validation Accuracy: {best_result['mean_validation_accuracy']:.4f} Â± {best_result['std_validation_accuracy']:.4f}")
            logger.info(f"   Test Accuracy: {best_result['mean_test_accuracy']:.4f} Â± {best_result['std_test_accuracy']:.4f}")
            logger.info(f"   Test F1 Score: {best_result['mean_test_f1']:.4f} Â± {best_result['std_test_f1']:.4f}")
            
            # çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            summary_df = pd.DataFrame([
                {
                    'experiment': exp_name,
                    'train_noise_types': '_'.join(result['train_noise_types']),
                    'test_noise_type': result['test_noise_type'],
                    'mean_validation_accuracy': result['mean_validation_accuracy'],
                    'std_validation_accuracy': result['std_validation_accuracy'],
                    'mean_test_accuracy': result['mean_test_accuracy'],
                    'std_test_accuracy': result['std_test_accuracy'],
                    'mean_test_f1': result['mean_test_f1'],
                    'std_test_f1': result['std_test_f1']
                }
                for exp_name, result in sorted_results
            ])
            
            summary_path = os.path.join(output_path, 'noise_combination_experiment_summary.csv')
            summary_df.to_csv(summary_path, index=False)
            logger.info(f"\nSummary saved to: {summary_path}")
            
            # è©³ç´°çµæœã‚’JSONã§ä¿å­˜
            detailed_path = os.path.join(output_path, 'noise_combination_experiment_detailed_results.json')
            with open(detailed_path, 'w') as f:
                json.dump(all_results, f, indent=2, default=str)
            logger.info(f"Detailed results saved to: {detailed_path}")
            
        else:
            logger.warning("No results from noise combination experiment")
        
        logger.info("Noise combination experiment completed!")

if __name__ == "__main__":
    main()
