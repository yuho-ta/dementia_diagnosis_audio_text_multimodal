(venv) PS C:\Users\yuho2\CogniAlign\modules> python silence_only_transformer.py --data_type noise_augmented
wandb: Currently logged in as: yuho2074tamura1217 (yuho2074tamura1217-keio-university-global-page) to
 https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in C:\Users\yuho2\CogniAlign\modules\wandb\run-20250903_190944-fysin904
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-smoke-11
wandb:  View project at https://wandb.ai/yuho2074tamura1217-keio-university-global-page/silence-transformer-classification
wandb:  View run at https://wandb.ai/yuho2074tamura1217-keio-university-global-page/silence-transformer-classification/runs/fysin904
Loading silence features with ID-based split...
Total unique IDs found: 282
Train IDs: 225, Test IDs: 57
Original train samples loaded: 225
Noise augmented train samples loaded: 225
Test samples loaded: 57
Original train data: 225 samples (CN: 69, AD: 156)
Noise augmented train data: 225 samples (CN: 69, AD: 156)
Test data: 57 samples (CN: 23, AD: 34)

==================================================
Training model with noise_augmented features
==================================================

### Fold 1 - NOISE_AUGMENTED Features
Fold 1 train label distribution:
  CN (0): 55 samples
  AD (1): 125 samples
  Total: 180 samples
Fold 1 validation label distribution:
  CN (0): 14 samples
  AD (1): 31 samples
  Total: 45 samples
Overall train dataset distribution:
  CN (0): 69 samples
  AD (1): 156 samples
  Total: 225 samples
Class distribution: Class 0 (CN): 55, Class 1 (AD): 125
Calculated weights: Class 0: 1.6364, Class 1: 0.7200
pos_weight for BCEWithLogitsLoss: 0.4400
Fold 1 pos_weight: 0.4400
Epoch 1/5: 100%|███████████████████████████████████████| 23/23 [03:40<00:00,  9.61s/it, loss=0.5886]
C:\Users\yuho2\CogniAlign\modules\venv\Lib\site-packages\sklearn\metrics\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Epoch 1: Train Loss: 0.4291, Val Loss: 0.4185, Val Accuracy: 0.3111
  Precision: 0.0000, Recall: 0.0000, F1: 0.0000, AUC: 0.5484
Epoch 2/5: 100%|███████████████████████████████████████| 23/23 [03:48<00:00,  9.95s/it, loss=0.4055]
Epoch 2: Train Loss: 0.4226, Val Loss: 0.4179, Val Accuracy: 0.5556
  Precision: 0.7895, Recall: 0.4839, F1: 0.6000, AUC: 0.6198
Epoch 3/5: 100%|███████████████████████████████████████| 23/23 [03:39<00:00,  9.55s/it, loss=0.5008] 
Epoch 3: Train Loss: 0.4255, Val Loss: 0.4176, Val Accuracy: 0.6889
  Precision: 0.6889, Recall: 1.0000, F1: 0.8158, AUC: 0.6452
Epoch 4/5: 100%|███████████████████████████████████████| 23/23 [03:45<00:00,  9.80s/it, loss=0.2983] 
Epoch 4: Train Loss: 0.4197, Val Loss: 0.4175, Val Accuracy: 0.6889
  Precision: 0.6889, Recall: 1.0000, F1: 0.8158, AUC: 0.6452
Epoch 5/5: 100%|███████████████████████████████████████| 23/23 [03:48<00:00,  9.95s/it, loss=0.4002] 
Epoch 5: Train Loss: 0.4214, Val Loss: 0.4174, Val Accuracy: 0.6889
  Precision: 0.6889, Recall: 1.0000, F1: 0.8158, AUC: 0.6567
Best model state restored for fold 1 testing
Fold 1 (noise_augmented) completed. Best F1-score: 0.8158, Best Accuracy: 0.6889

### Fold 2 - NOISE_AUGMENTED Features
Fold 2 train label distribution:
  CN (0): 55 samples
  AD (1): 125 samples
  Total: 180 samples
Fold 2 validation label distribution:
  CN (0): 14 samples
  AD (1): 31 samples
  Total: 45 samples
Overall train dataset distribution:
  CN (0): 69 samples
  AD (1): 156 samples
  Total: 225 samples
Class distribution: Class 0 (CN): 55, Class 1 (AD): 125
Calculated weights: Class 0: 1.6364, Class 1: 0.7200
pos_weight for BCEWithLogitsLoss: 0.4400
Fold 2 pos_weight: 0.4400
Epoch 1/5: 100%|███████████████████████████████████████| 23/23 [04:05<00:00, 10.67s/it, loss=0.3040]
Epoch 1: Train Loss: 0.4219, Val Loss: 0.4186, Val Accuracy: 0.6889
  Precision: 0.6889, Recall: 1.0000, F1: 0.8158, AUC: 0.2857
Epoch 2/5: 100%|███████████████████████████████████████| 23/23 [03:49<00:00,  9.99s/it, loss=0.3042] 
Epoch 2: Train Loss: 0.4213, Val Loss: 0.4186, Val Accuracy: 0.5778
  Precision: 0.6500, Recall: 0.8387, F1: 0.7324, AUC: 0.3502
Epoch 3/5: 100%|███████████████████████████████████████| 23/23 [03:47<00:00,  9.89s/it, loss=0.3019] 
Epoch 3: Train Loss: 0.4208, Val Loss: 0.4184, Val Accuracy: 0.6889
  Precision: 0.6889, Recall: 1.0000, F1: 0.8158, AUC: 0.4055
Epoch 4/5: 100%|███████████████████████████████████████| 23/23 [03:38<00:00,  9.49s/it, loss=0.4970]
Epoch 4: Train Loss: 0.4245, Val Loss: 0.4182, Val Accuracy: 0.6889
  Precision: 0.6889, Recall: 1.0000, F1: 0.8158, AUC: 0.5115
Epoch 5/5: 100%|███████████████████████████████████████| 23/23 [03:46<00:00,  9.83s/it, loss=0.4024] 
Epoch 5: Train Loss: 0.4224, Val Loss: 0.4181, Val Accuracy: 0.6889
  Precision: 0.6889, Recall: 1.0000, F1: 0.8158, AUC: 0.5230
Best model state restored for fold 2 testing
Fold 2 (noise_augmented) completed. Best F1-score: 0.8158, Best Accuracy: 0.6889

### Fold 3 - NOISE_AUGMENTED Features
Fold 3 train label distribution:
  CN (0): 55 samples
  AD (1): 125 samples
  Total: 180 samples
Fold 3 validation label distribution:
  CN (0): 14 samples
  AD (1): 31 samples
  Total: 45 samples
Overall train dataset distribution:
  CN (0): 69 samples
  AD (1): 156 samples
  Total: 225 samples
Class distribution: Class 0 (CN): 55, Class 1 (AD): 125
Calculated weights: Class 0: 1.6364, Class 1: 0.7200
pos_weight for BCEWithLogitsLoss: 0.4400
Fold 3 pos_weight: 0.4400
Epoch 1/5: 100%|███████████████████████████████████████| 23/23 [03:41<00:00,  9.63s/it, loss=0.4054]
C:\Users\yuho2\CogniAlign\modules\venv\Lib\site-packages\sklearn\metrics\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Epoch 1: Train Loss: 0.4242, Val Loss: 0.4189, Val Accuracy: 0.3111
  Precision: 0.0000, Recall: 0.0000, F1: 0.0000, AUC: 0.4908
Epoch 2/5: 100%|███████████████████████████████████████| 23/23 [03:34<00:00,  9.34s/it, loss=0.3128] 
C:\Users\yuho2\CogniAlign\modules\venv\Lib\site-packages\sklearn\metrics\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Epoch 2: Train Loss: 0.4209, Val Loss: 0.4185, Val Accuracy: 0.3111
  Precision: 0.0000, Recall: 0.0000, F1: 0.0000, AUC: 0.5138
Epoch 3/5: 100%|███████████████████████████████████████| 23/23 [03:49<00:00,  9.99s/it, loss=0.4958] 
C:\Users\yuho2\CogniAlign\modules\venv\Lib\site-packages\sklearn\metrics\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Epoch 3: Train Loss: 0.4248, Val Loss: 0.4181, Val Accuracy: 0.3111
  Precision: 0.0000, Recall: 0.0000, F1: 0.0000, AUC: 0.4931
Epoch 4/5: 100%|███████████████████████████████████████| 23/23 [03:30<00:00,  9.17s/it, loss=0.4980] 
Epoch 4: Train Loss: 0.4244, Val Loss: 0.4176, Val Accuracy: 0.6889
  Precision: 0.6977, Recall: 0.9677, F1: 0.8108, AUC: 0.5023
Epoch 5/5: 100%|███████████████████████████████████████| 23/23 [03:50<00:00, 10.02s/it, loss=0.2982] 
Epoch 5: Train Loss: 0.4198, Val Loss: 0.4176, Val Accuracy: 0.7111
  Precision: 0.7045, Recall: 1.0000, F1: 0.8267, AUC: 0.5023
Best model state restored for fold 3 testing
Fold 3 (noise_augmented) completed. Best F1-score: 0.8267, Best Accuracy: 0.7111

### Fold 4 - NOISE_AUGMENTED Features
Fold 4 train label distribution:
  CN (0): 55 samples
  AD (1): 125 samples
  Total: 180 samples
Fold 4 validation label distribution:
  CN (0): 14 samples
  AD (1): 31 samples
  Total: 45 samples
Overall train dataset distribution:
  CN (0): 69 samples
  AD (1): 156 samples
  Total: 225 samples
Class distribution: Class 0 (CN): 55, Class 1 (AD): 125
Calculated weights: Class 0: 1.6364, Class 1: 0.7200
pos_weight for BCEWithLogitsLoss: 0.4400
Fold 4 pos_weight: 0.4400
Epoch 1/5: 100%|███████████████████████████████████████| 23/23 [03:49<00:00, 10.00s/it, loss=0.3146]
C:\Users\yuho2\CogniAlign\modules\venv\Lib\site-packages\sklearn\metrics\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Epoch 1: Train Loss: 0.4219, Val Loss: 0.4188, Val Accuracy: 0.3111
  Precision: 0.0000, Recall: 0.0000, F1: 0.0000, AUC: 0.4770
Epoch 2/5: 100%|███████████████████████████████████████| 23/23 [03:37<00:00,  9.45s/it, loss=0.4062]
C:\Users\yuho2\CogniAlign\modules\venv\Lib\site-packages\sklearn\metrics\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Epoch 2: Train Loss: 0.4225, Val Loss: 0.4188, Val Accuracy: 0.3111
  Precision: 0.0000, Recall: 0.0000, F1: 0.0000, AUC: 0.5899
Epoch 3/5: 100%|███████████████████████████████████████| 23/23 [03:49<00:00,  9.99s/it, loss=0.3191] 
C:\Users\yuho2\CogniAlign\modules\venv\Lib\site-packages\sklearn\metrics\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Epoch 3: Train Loss: 0.4221, Val Loss: 0.4187, Val Accuracy: 0.3111
  Precision: 0.0000, Recall: 0.0000, F1: 0.0000, AUC: 0.5968
Epoch 4/5: 100%|███████████████████████████████████████| 23/23 [03:37<00:00,  9.48s/it, loss=0.3157] 
C:\Users\yuho2\CogniAlign\modules\venv\Lib\site-packages\sklearn\metrics\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Epoch 4: Train Loss: 0.4197, Val Loss: 0.4185, Val Accuracy: 0.3111
  Precision: 0.0000, Recall: 0.0000, F1: 0.0000, AUC: 0.6152
Epoch 5/5: 100%|███████████████████████████████████████| 23/23 [03:49<00:00,  9.99s/it, loss=0.4909] 
C:\Users\yuho2\CogniAlign\modules\venv\Lib\site-packages\sklearn\metrics\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Epoch 5: Train Loss: 0.4244, Val Loss: 0.4184, Val Accuracy: 0.3111
  Precision: 0.0000, Recall: 0.0000, F1: 0.0000, AUC: 0.6198
Warning: No best model state available for fold 4
C:\Users\yuho2\CogniAlign\modules\venv\Lib\site-packages\sklearn\metrics\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Fold 4 (noise_augmented) completed. Best F1-score: 0.0000, Best Accuracy: 0.3111

### Fold 5 - NOISE_AUGMENTED Features
Fold 5 train label distribution:
  CN (0): 56 samples
  AD (1): 124 samples
  Total: 180 samples
Fold 5 validation label distribution:
  CN (0): 13 samples
  AD (1): 32 samples
  Total: 45 samples
Overall train dataset distribution:
  CN (0): 69 samples
  AD (1): 156 samples
  Total: 225 samples
Class distribution: Class 0 (CN): 56, Class 1 (AD): 124
Calculated weights: Class 0: 1.6071, Class 1: 0.7258
pos_weight for BCEWithLogitsLoss: 0.4516
Fold 5 pos_weight: 0.4516
Epoch 1/5: 100%|███████████████████████████████████████| 23/23 [03:39<00:00,  9.55s/it, loss=0.6261]
Epoch 1: Train Loss: 0.4375, Val Loss: 0.4142, Val Accuracy: 0.7111
  Precision: 0.7111, Recall: 1.0000, F1: 0.8312, AUC: 0.4808
Epoch 2/5: 100%|███████████████████████████████████████| 23/23 [03:47<00:00,  9.89s/it, loss=0.3973]
Epoch 2: Train Loss: 0.4304, Val Loss: 0.4141, Val Accuracy: 0.7111
  Precision: 0.7111, Recall: 1.0000, F1: 0.8312, AUC: 0.6587
Epoch 3/5: 100%|███████████████████████████████████████| 23/23 [03:47<00:00,  9.90s/it, loss=0.4104]
Epoch 3: Train Loss: 0.4303, Val Loss: 0.4147, Val Accuracy: 0.7111
  Precision: 0.7111, Recall: 1.0000, F1: 0.8312, AUC: 0.6779
Epoch 4/5: 100%|███████████████████████████████████████| 23/23 [03:47<00:00,  9.87s/it, loss=0.4084]
Epoch 4: Train Loss: 0.4299, Val Loss: 0.4143, Val Accuracy: 0.7111
  Precision: 0.7111, Recall: 1.0000, F1: 0.8312, AUC: 0.6971
Epoch 5/5: 100%|███████████████████████████████████████| 23/23 [03:06<00:00,  8.11s/it, loss=0.4137]
Epoch 5: Train Loss: 0.4300, Val Loss: 0.4142, Val Accuracy: 0.7111
  Precision: 0.7111, Recall: 1.0000, F1: 0.8312, AUC: 0.7019
Best model state restored for fold 5 testing
Fold 5 (noise_augmented) completed. Best F1-score: 0.8312, Best Accuracy: 0.7111

=== AD Sample Usage Across All Folds (NOISE_AUGMENTED) ===
Fold 1: 156 AD samples
Fold 2: 156 AD samples
Fold 3: 156 AD samples
Fold 4: 156 AD samples
Fold 5: 156 AD samples
Total unique AD samples used across all folds: 156
Total AD samples in train dataset: 156
All AD samples used: Yes

=== Final Results (NOISE_AUGMENTED) ===
   fold        data_type   best_f1  best_val_accuracy  best_val_loss  final_val_accuracy  final_val_loss
0     1  noise_augmented  0.815789           0.688889       0.417416            0.688889        0.417416
1     2  noise_augmented  0.815789           0.688889       0.418128            0.688889        0.418128
2     3  noise_augmented  0.826667           0.711111       0.417558            0.711111        0.417558
3     4  noise_augmented  0.000000           0.311111       0.418413            0.311111        0.418413
4     5  noise_augmented  0.831169           0.711111       0.414068            0.711111        0.414234

=== Test Performance Across Folds (NOISE_AUGMENTED) (Average ± Std) ===
Test F1-score: 0.4768 ± 0.3471
Test Accuracy: 0.5368 ± 0.1050
Test AUC: 0.5857 ± 0.1570

=== Best Values Across Epochs (NOISE_AUGMENTED) (Average ± Std) ===
Best F1-score: 0.6579 ± 0.3678
Best Accuracy: 0.6222 ± 0.1743
Best Loss: 0.4171 ± 0.0018

=== Test Data Evaluation (NOISE_AUGMENTED) ===
Test data contains 57 samples
Test CN samples: 23, Test AD samples: 34

NOISE_AUGMENTED model training completed!

============================================================
FINAL PERFORMANCE SUMMARY - NOISE AUGMENTED MODEL
============================================================
Test F1-Score: 0.4768 ± 0.3471
Test Accuracy: 0.5368 ± 0.1050
Test AUC: 0.5857 ± 0.1570
Cross-validation folds: 5
Training samples: 225
Test samples: 57
wandb:
wandb:
wandb: Run history:
wandb:         dataset/noise_augmented_train_ad_samples ▁
wandb:         dataset/noise_augmented_train_cn_samples ▁
wandb:            dataset/noise_augmented_train_samples ▁
wandb:                dataset/original_train_ad_samples ▁
wandb:                dataset/original_train_cn_samples ▁
wandb:                   dataset/original_train_samples ▁
wandb:                          dataset/test_ad_samples ▁
wandb:                          dataset/test_cn_samples ▁
wandb:                             dataset/test_samples ▁
wandb:                            dataset/total_samples ▁
wandb:                           final_summary/cv_folds ▁
wandb:                      final_summary/test_accuracy ▁
wandb:                  final_summary/test_accuracy_std ▁
wandb:                           final_summary/test_auc ▁
wandb:                       final_summary/test_auc_std ▁
wandb:                      final_summary/test_f1_score ▁
wandb:                  final_summary/test_f1_score_std ▁
wandb:                       final_summary/test_samples ▁
wandb:                   final_summary/training_samples ▁
wandb:         fold_1_noise_augmented_transformer/epoch ▁▃▅▆█
wandb: fold_1_noise_augmented_transformer/learning_rate █▆▄▃▁
wandb:    fold_1_noise_augmented_transformer/train_loss █▃▅▁▂
wandb:  fold_1_noise_augmented_transformer/val_accuracy ▁▆███
wandb:   fold_1_noise_augmented_transformer/val_auc_roc ▁▆▇▇█
wandb:        fold_1_noise_augmented_transformer/val_f1 ▁▆███
wandb:      fold_1_noise_augmented_transformer/val_loss █▄▂▁▁
wandb: fold_1_noise_augmented_transformer/val_precision ▁█▇▇▇
wandb:    fold_1_noise_augmented_transformer/val_recall ▁▄███
wandb:         fold_2_noise_augmented_transformer/epoch ▁▃▅▆█
wandb: fold_2_noise_augmented_transformer/learning_rate █▆▄▃▁
wandb:    fold_2_noise_augmented_transformer/train_loss ▃▂▁█▄
wandb:  fold_2_noise_augmented_transformer/val_accuracy █▁███
wandb:   fold_2_noise_augmented_transformer/val_auc_roc ▁▃▅██
wandb:        fold_2_noise_augmented_transformer/val_f1 █▁███
wandb:      fold_2_noise_augmented_transformer/val_loss ██▅▂▁
wandb: fold_2_noise_augmented_transformer/val_precision █▁███
wandb:    fold_2_noise_augmented_transformer/val_recall █▁███
wandb:         fold_3_noise_augmented_transformer/epoch ▁▃▅▆█
wandb: fold_3_noise_augmented_transformer/learning_rate █▆▄▃▁
wandb:    fold_3_noise_augmented_transformer/train_loss ▇▂█▇▁
wandb:  fold_3_noise_augmented_transformer/val_accuracy ▁▁▁██
wandb:   fold_3_noise_augmented_transformer/val_auc_roc ▁█▂▄▄
wandb:        fold_3_noise_augmented_transformer/val_f1 ▁▁▁██
wandb:      fold_3_noise_augmented_transformer/val_loss █▆▄▁▁
wandb: fold_3_noise_augmented_transformer/val_precision ▁▁▁██
wandb:    fold_3_noise_augmented_transformer/val_recall ▁▁▁██
wandb:         fold_4_noise_augmented_transformer/epoch ▁▃▅▆█
wandb: fold_4_noise_augmented_transformer/learning_rate █▆▄▃▁
wandb:    fold_4_noise_augmented_transformer/train_loss ▄▅▅▁█
wandb:  fold_4_noise_augmented_transformer/val_accuracy ▁▁▁▁▁
wandb:   fold_4_noise_augmented_transformer/val_auc_roc ▁▇▇██
wandb:        fold_4_noise_augmented_transformer/val_f1 ▁▁▁▁▁
wandb:      fold_4_noise_augmented_transformer/val_loss ▇█▅▂▁
wandb: fold_4_noise_augmented_transformer/val_precision ▁▁▁▁▁
wandb:    fold_4_noise_augmented_transformer/val_recall ▁▁▁▁▁
wandb:         fold_5_noise_augmented_transformer/epoch ▁▃▅▆█
wandb: fold_5_noise_augmented_transformer/learning_rate █▆▄▃▁
wandb:    fold_5_noise_augmented_transformer/train_loss █▁▁▁▁
wandb:  fold_5_noise_augmented_transformer/val_accuracy ▁▁▁▁▁
wandb:   fold_5_noise_augmented_transformer/val_auc_roc ▁▇▇██
wandb:        fold_5_noise_augmented_transformer/val_f1 ▁▁▁▁▁
wandb:      fold_5_noise_augmented_transformer/val_loss ▃▁█▄▃
wandb: fold_5_noise_augmented_transformer/val_precision ▁▁▁▁▁
wandb:    fold_5_noise_augmented_transformer/val_recall ▁▁▁▁▁
wandb:         noise_augmented_final/mean_best_accuracy ▁
wandb:               noise_augmented_final/mean_best_f1 ▁
wandb:             noise_augmented_final/mean_best_loss ▁
wandb:          noise_augmented_final/std_best_accuracy ▁
wandb:                noise_augmented_final/std_best_f1 ▁
wandb:              noise_augmented_final/std_best_loss ▁
wandb:                   noise_augmented_fold_1/best_f1 ▁
wandb:         noise_augmented_fold_1/best_val_accuracy ▁
wandb:             noise_augmented_fold_1/best_val_loss ▁
wandb:        noise_augmented_fold_1/final_val_accuracy ▁
wandb:            noise_augmented_fold_1/final_val_loss ▁
wandb:                noise_augmented_fold_1/pos_weight ▁
wandb:             noise_augmented_fold_1/test_accuracy ▁
wandb:                  noise_augmented_fold_1/test_auc ▁
wandb:                   noise_augmented_fold_1/test_f1 ▁
wandb:                 noise_augmented_fold_1/test_loss ▁
wandb:                  noise_augmented_fold_1/train_ad ▁
wandb:            noise_augmented_fold_1/train_ad_ratio ▁
wandb:                  noise_augmented_fold_1/train_cn ▁
wandb:            noise_augmented_fold_1/train_cn_ratio ▁
wandb:               noise_augmented_fold_1/train_total ▁
wandb:                    noise_augmented_fold_1/val_ad ▁
wandb:              noise_augmented_fold_1/val_ad_ratio ▁
wandb:                    noise_augmented_fold_1/val_cn ▁
wandb:              noise_augmented_fold_1/val_cn_ratio ▁
wandb:                 noise_augmented_fold_1/val_total ▁
wandb:                   noise_augmented_fold_2/best_f1 ▁
wandb:         noise_augmented_fold_2/best_val_accuracy ▁
wandb:             noise_augmented_fold_2/best_val_loss ▁
wandb:        noise_augmented_fold_2/final_val_accuracy ▁
wandb:            noise_augmented_fold_2/final_val_loss ▁
wandb:                noise_augmented_fold_2/pos_weight ▁
wandb:             noise_augmented_fold_2/test_accuracy ▁
wandb:                  noise_augmented_fold_2/test_auc ▁
wandb:                   noise_augmented_fold_2/test_f1 ▁
wandb:                 noise_augmented_fold_2/test_loss ▁
wandb:                  noise_augmented_fold_2/train_ad ▁
wandb:            noise_augmented_fold_2/train_ad_ratio ▁
wandb:                  noise_augmented_fold_2/train_cn ▁
wandb:            noise_augmented_fold_2/train_cn_ratio ▁
wandb:               noise_augmented_fold_2/train_total ▁
wandb:                    noise_augmented_fold_2/val_ad ▁
wandb:              noise_augmented_fold_2/val_ad_ratio ▁
wandb:                    noise_augmented_fold_2/val_cn ▁
wandb:              noise_augmented_fold_2/val_cn_ratio ▁
wandb:                 noise_augmented_fold_2/val_total ▁
wandb:                   noise_augmented_fold_3/best_f1 ▁
wandb:         noise_augmented_fold_3/best_val_accuracy ▁
wandb:             noise_augmented_fold_3/best_val_loss ▁
wandb:        noise_augmented_fold_3/final_val_accuracy ▁
wandb:            noise_augmented_fold_3/final_val_loss ▁
wandb:                noise_augmented_fold_3/pos_weight ▁
wandb:             noise_augmented_fold_3/test_accuracy ▁
wandb:                  noise_augmented_fold_3/test_auc ▁
wandb:                   noise_augmented_fold_3/test_f1 ▁
wandb:                 noise_augmented_fold_3/test_loss ▁
wandb:                  noise_augmented_fold_3/train_ad ▁
wandb:            noise_augmented_fold_3/train_ad_ratio ▁
wandb:                  noise_augmented_fold_3/train_cn ▁
wandb:            noise_augmented_fold_3/train_cn_ratio ▁
wandb:               noise_augmented_fold_3/train_total ▁
wandb:                    noise_augmented_fold_3/val_ad ▁
wandb:              noise_augmented_fold_3/val_ad_ratio ▁
wandb:                    noise_augmented_fold_3/val_cn ▁
wandb:              noise_augmented_fold_3/val_cn_ratio ▁
wandb:                 noise_augmented_fold_3/val_total ▁
wandb:                   noise_augmented_fold_4/best_f1 ▁
wandb:         noise_augmented_fold_4/best_val_accuracy ▁
wandb:             noise_augmented_fold_4/best_val_loss ▁
wandb:        noise_augmented_fold_4/final_val_accuracy ▁
wandb:            noise_augmented_fold_4/final_val_loss ▁
wandb:                noise_augmented_fold_4/pos_weight ▁
wandb:             noise_augmented_fold_4/test_accuracy ▁
wandb:                  noise_augmented_fold_4/test_auc ▁
wandb:                   noise_augmented_fold_4/test_f1 ▁
wandb:                 noise_augmented_fold_4/test_loss ▁
wandb:                  noise_augmented_fold_4/train_ad ▁
wandb:            noise_augmented_fold_4/train_ad_ratio ▁
wandb:                  noise_augmented_fold_4/train_cn ▁
wandb:            noise_augmented_fold_4/train_cn_ratio ▁
wandb:               noise_augmented_fold_4/train_total ▁
wandb:                    noise_augmented_fold_4/val_ad ▁
wandb:              noise_augmented_fold_4/val_ad_ratio ▁
wandb:                    noise_augmented_fold_4/val_cn ▁
wandb:              noise_augmented_fold_4/val_cn_ratio ▁
wandb:                 noise_augmented_fold_4/val_total ▁
wandb:                   noise_augmented_fold_5/best_f1 ▁
wandb:         noise_augmented_fold_5/best_val_accuracy ▁
wandb:             noise_augmented_fold_5/best_val_loss ▁
wandb:        noise_augmented_fold_5/final_val_accuracy ▁
wandb:            noise_augmented_fold_5/final_val_loss ▁
wandb:                noise_augmented_fold_5/pos_weight ▁
wandb:             noise_augmented_fold_5/test_accuracy ▁
wandb:                  noise_augmented_fold_5/test_auc ▁
wandb:                   noise_augmented_fold_5/test_f1 ▁
wandb:                 noise_augmented_fold_5/test_loss ▁
wandb:                  noise_augmented_fold_5/train_ad ▁
wandb:            noise_augmented_fold_5/train_ad_ratio ▁
wandb:                  noise_augmented_fold_5/train_cn ▁
wandb:            noise_augmented_fold_5/train_cn_ratio ▁
wandb:               noise_augmented_fold_5/train_total ▁
wandb:                    noise_augmented_fold_5/val_ad ▁
wandb:              noise_augmented_fold_5/val_ad_ratio ▁
wandb:                    noise_augmented_fold_5/val_cn ▁
wandb:              noise_augmented_fold_5/val_cn_ratio ▁
wandb:                 noise_augmented_fold_5/val_total ▁
wandb:               noise_augmented_test/mean_accuracy ▁
wandb:                    noise_augmented_test/mean_auc ▁
wandb:                     noise_augmented_test/mean_f1 ▁
wandb:                noise_augmented_test/std_accuracy ▁
wandb:                     noise_augmented_test/std_auc ▁
wandb:                      noise_augmented_test/std_f1 ▁
wandb:
wandb: Run summary:
wandb:         dataset/noise_augmented_train_ad_samples 156
wandb:         dataset/noise_augmented_train_cn_samples 69
wandb:            dataset/noise_augmented_train_samples 225
wandb:                dataset/original_train_ad_samples 156
wandb:                dataset/original_train_cn_samples 69
wandb:                   dataset/original_train_samples 225
wandb:                          dataset/test_ad_samples 34
wandb:                          dataset/test_cn_samples 23
wandb:                             dataset/test_samples 57
wandb:                            dataset/total_samples 507
wandb:                           final_summary/cv_folds 5
wandb:                          final_summary/data_type noise_augmented
wandb:                      final_summary/test_accuracy 0.53684
wandb:                  final_summary/test_accuracy_std 0.10503
wandb:                           final_summary/test_auc 0.58568
wandb:                       final_summary/test_auc_std 0.15703
wandb:                      final_summary/test_f1_score 0.47684
wandb:                  final_summary/test_f1_score_std 0.34712
wandb:                       final_summary/test_samples 57
wandb:                   final_summary/training_samples 225
wandb:         fold_1_noise_augmented_transformer/epoch 5
wandb: fold_1_noise_augmented_transformer/learning_rate 0.0
wandb:    fold_1_noise_augmented_transformer/train_loss 0.42142
wandb:  fold_1_noise_augmented_transformer/val_accuracy 0.68889
wandb:   fold_1_noise_augmented_transformer/val_auc_roc 0.65668
wandb:        fold_1_noise_augmented_transformer/val_f1 0.81579
wandb:      fold_1_noise_augmented_transformer/val_loss 0.41742
wandb: fold_1_noise_augmented_transformer/val_precision 0.68889
wandb:    fold_1_noise_augmented_transformer/val_recall 1
wandb:         fold_2_noise_augmented_transformer/epoch 5
wandb: fold_2_noise_augmented_transformer/learning_rate 0.0
wandb:    fold_2_noise_augmented_transformer/train_loss 0.42236
wandb:  fold_2_noise_augmented_transformer/val_accuracy 0.68889
wandb:   fold_2_noise_augmented_transformer/val_auc_roc 0.52304
wandb:        fold_2_noise_augmented_transformer/val_f1 0.81579
wandb:      fold_2_noise_augmented_transformer/val_loss 0.41813
wandb: fold_2_noise_augmented_transformer/val_precision 0.68889
wandb:    fold_2_noise_augmented_transformer/val_recall 1
wandb:         fold_3_noise_augmented_transformer/epoch 5
wandb: fold_3_noise_augmented_transformer/learning_rate 0.0
wandb:    fold_3_noise_augmented_transformer/train_loss 0.41982
wandb:  fold_3_noise_augmented_transformer/val_accuracy 0.71111
wandb:   fold_3_noise_augmented_transformer/val_auc_roc 0.5023
wandb:        fold_3_noise_augmented_transformer/val_f1 0.82667
wandb:      fold_3_noise_augmented_transformer/val_loss 0.41756
wandb: fold_3_noise_augmented_transformer/val_precision 0.70455
wandb:    fold_3_noise_augmented_transformer/val_recall 1
wandb:         fold_4_noise_augmented_transformer/epoch 5
wandb: fold_4_noise_augmented_transformer/learning_rate 0.0
wandb:    fold_4_noise_augmented_transformer/train_loss 0.42435
wandb:  fold_4_noise_augmented_transformer/val_accuracy 0.31111
wandb:   fold_4_noise_augmented_transformer/val_auc_roc 0.61982
wandb:        fold_4_noise_augmented_transformer/val_f1 0
wandb:      fold_4_noise_augmented_transformer/val_loss 0.41841
wandb: fold_4_noise_augmented_transformer/val_precision 0
wandb:    fold_4_noise_augmented_transformer/val_recall 0
wandb:         fold_5_noise_augmented_transformer/epoch 5
wandb: fold_5_noise_augmented_transformer/learning_rate 0.0
wandb:    fold_5_noise_augmented_transformer/train_loss 0.43003
wandb:  fold_5_noise_augmented_transformer/val_accuracy 0.71111
wandb:   fold_5_noise_augmented_transformer/val_auc_roc 0.70192
wandb:        fold_5_noise_augmented_transformer/val_f1 0.83117
wandb:      fold_5_noise_augmented_transformer/val_loss 0.41423
wandb: fold_5_noise_augmented_transformer/val_precision 0.71111
wandb:    fold_5_noise_augmented_transformer/val_recall 1
wandb:         noise_augmented_final/mean_best_accuracy 0.62222
wandb:               noise_augmented_final/mean_best_f1 0.65788
wandb:             noise_augmented_final/mean_best_loss 0.41712
wandb:          noise_augmented_final/std_best_accuracy 0.17427
wandb:                noise_augmented_final/std_best_f1 0.36783
wandb:              noise_augmented_final/std_best_loss 0.00175
wandb:                   noise_augmented_fold_1/best_f1 0.81579
wandb:         noise_augmented_fold_1/best_val_accuracy 0.68889
wandb:             noise_augmented_fold_1/best_val_loss 0.41742
wandb:        noise_augmented_fold_1/final_val_accuracy 0.68889
wandb:            noise_augmented_fold_1/final_val_loss 0.41742
wandb:                noise_augmented_fold_1/pos_weight 0.44
wandb:             noise_augmented_fold_1/test_accuracy 0.66667
wandb:                  noise_augmented_fold_1/test_auc 0.72251
wandb:                   noise_augmented_fold_1/test_f1 0.78161
wandb:                 noise_augmented_fold_1/test_loss 0.44396
wandb:                  noise_augmented_fold_1/train_ad 125
wandb:            noise_augmented_fold_1/train_ad_ratio 0.69444
wandb:                  noise_augmented_fold_1/train_cn 55
wandb:            noise_augmented_fold_1/train_cn_ratio 0.30556
wandb:               noise_augmented_fold_1/train_total 180
wandb:                    noise_augmented_fold_1/val_ad 31
wandb:              noise_augmented_fold_1/val_ad_ratio 0.68889
wandb:                    noise_augmented_fold_1/val_cn 14
wandb:              noise_augmented_fold_1/val_cn_ratio 0.31111
wandb:                 noise_augmented_fold_1/val_total 45
wandb:                   noise_augmented_fold_2/best_f1 0.81579
wandb:         noise_augmented_fold_2/best_val_accuracy 0.68889
wandb:             noise_augmented_fold_2/best_val_loss 0.41813
wandb:        noise_augmented_fold_2/final_val_accuracy 0.68889
wandb:            noise_augmented_fold_2/final_val_loss 0.41813
wandb:                noise_augmented_fold_2/pos_weight 0.44
wandb:             noise_augmented_fold_2/test_accuracy 0.59649
wandb:                  noise_augmented_fold_2/test_auc 0.68286
wandb:                   noise_augmented_fold_2/test_f1 0.74725
wandb:                 noise_augmented_fold_2/test_loss 0.44562
wandb:                  noise_augmented_fold_2/train_ad 125
wandb:            noise_augmented_fold_2/train_ad_ratio 0.69444
wandb:                  noise_augmented_fold_2/train_cn 55
wandb:            noise_augmented_fold_2/train_cn_ratio 0.30556
wandb:               noise_augmented_fold_2/train_total 180
wandb:                    noise_augmented_fold_2/val_ad 31
wandb:              noise_augmented_fold_2/val_ad_ratio 0.68889
wandb:                    noise_augmented_fold_2/val_cn 14
wandb:              noise_augmented_fold_2/val_cn_ratio 0.31111
wandb:                 noise_augmented_fold_2/val_total 45
wandb:                   noise_augmented_fold_3/best_f1 0.82667
wandb:         noise_augmented_fold_3/best_val_accuracy 0.71111
wandb:             noise_augmented_fold_3/best_val_loss 0.41756
wandb:        noise_augmented_fold_3/final_val_accuracy 0.71111
wandb:            noise_augmented_fold_3/final_val_loss 0.41756
wandb:                noise_augmented_fold_3/pos_weight 0.44
wandb:             noise_augmented_fold_3/test_accuracy 0.42105
wandb:                  noise_augmented_fold_3/test_auc 0.3977
wandb:                   noise_augmented_fold_3/test_f1 0.10811
wandb:                 noise_augmented_fold_3/test_loss 0.44459
wandb:                  noise_augmented_fold_3/train_ad 125
wandb:            noise_augmented_fold_3/train_ad_ratio 0.69444
wandb:                  noise_augmented_fold_3/train_cn 55
wandb:            noise_augmented_fold_3/train_cn_ratio 0.30556
wandb:               noise_augmented_fold_3/train_total 180
wandb:                    noise_augmented_fold_3/val_ad 31
wandb:              noise_augmented_fold_3/val_ad_ratio 0.68889
wandb:                    noise_augmented_fold_3/val_cn 14
wandb:              noise_augmented_fold_3/val_cn_ratio 0.31111
wandb:                 noise_augmented_fold_3/val_total 45
wandb:                   noise_augmented_fold_4/best_f1 0
wandb:         noise_augmented_fold_4/best_val_accuracy 0.31111
wandb:             noise_augmented_fold_4/best_val_loss 0.41841
wandb:        noise_augmented_fold_4/final_val_accuracy 0.31111
wandb:            noise_augmented_fold_4/final_val_loss 0.41841
wandb:                noise_augmented_fold_4/pos_weight 0.44
wandb:             noise_augmented_fold_4/test_accuracy 0.40351
wandb:                  noise_augmented_fold_4/test_auc 0.3913
wandb:                   noise_augmented_fold_4/test_f1 0
wandb:                 noise_augmented_fold_4/test_loss 0.44315
wandb:                  noise_augmented_fold_4/train_ad 125
wandb:            noise_augmented_fold_4/train_ad_ratio 0.69444
wandb:                  noise_augmented_fold_4/train_cn 55
wandb:            noise_augmented_fold_4/train_cn_ratio 0.30556
wandb:               noise_augmented_fold_4/train_total 180
wandb:                    noise_augmented_fold_4/val_ad 31
wandb:              noise_augmented_fold_4/val_ad_ratio 0.68889
wandb:                    noise_augmented_fold_4/val_cn 14
wandb:              noise_augmented_fold_4/val_cn_ratio 0.31111
wandb:                 noise_augmented_fold_4/val_total 45
wandb:                   noise_augmented_fold_5/best_f1 0.83117
wandb:         noise_augmented_fold_5/best_val_accuracy 0.71111
wandb:             noise_augmented_fold_5/best_val_loss 0.41407
wandb:        noise_augmented_fold_5/final_val_accuracy 0.71111
wandb:            noise_augmented_fold_5/final_val_loss 0.41423
wandb:                noise_augmented_fold_5/pos_weight 0.45161
wandb:             noise_augmented_fold_5/test_accuracy 0.59649
wandb:                  noise_augmented_fold_5/test_auc 0.73402
wandb:                   noise_augmented_fold_5/test_f1 0.74725
wandb:                 noise_augmented_fold_5/test_loss 0.45017
wandb:                  noise_augmented_fold_5/train_ad 124
wandb:            noise_augmented_fold_5/train_ad_ratio 0.68889
wandb:                  noise_augmented_fold_5/train_cn 56
wandb:            noise_augmented_fold_5/train_cn_ratio 0.31111
wandb:               noise_augmented_fold_5/train_total 180
wandb:                    noise_augmented_fold_5/val_ad 32
wandb:              noise_augmented_fold_5/val_ad_ratio 0.71111
wandb:                    noise_augmented_fold_5/val_cn 13
wandb:              noise_augmented_fold_5/val_cn_ratio 0.28889
wandb:                 noise_augmented_fold_5/val_total 45
wandb:               noise_augmented_test/mean_accuracy 0.53684
wandb:                    noise_augmented_test/mean_auc 0.58568
wandb:                     noise_augmented_test/mean_f1 0.47684
wandb:                noise_augmented_test/std_accuracy 0.10503
wandb:                     noise_augmented_test/std_auc 0.15703
wandb:                      noise_augmented_test/std_f1 0.34712
wandb:
wandb:  View run gallant-smoke-11 at: https://wandb.ai/yuho2074tamura1217-keio-university-global-page/silence-transformer-classification/runs/fysin904
wandb:  View project at: https://wandb.ai/yuho2074tamura1217-keio-university-global-page/silence-transformer-classification
wandb: Synced 5 W&B file(s), 7 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: .\wandb\run-20250903_190944-fysin904\logs
(venv) PS C:\Users\yuho2\CogniAlign\modules> 